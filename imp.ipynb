{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d267b1-daf7-4dbe-aeb0-a492a3f816ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install chess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7297449f-5b76-4943-8df9-419a2b602862",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import chess\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "class PieceWiseSelfAttention(nn.Module):\n",
    "    def __init__(self, embedding_dim, num_heads):\n",
    "        super(PieceWiseSelfAttention, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = embedding_dim // num_heads\n",
    "        self.query = nn.Linear(embedding_dim, embedding_dim)\n",
    "        self.key = nn.Linear(embedding_dim, embedding_dim)\n",
    "        self.value = nn.Linear(embedding_dim, embedding_dim)\n",
    "        self.attention_weights = None\n",
    "\n",
    "    def forward(self, x, piece_type):\n",
    "        batch_size, seq_length, _ = x.size()\n",
    "        q = self.query(x).view(batch_size, seq_length, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        k = self.key(x).view(batch_size, seq_length, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        v = self.value(x).view(batch_size, seq_length, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        \n",
    "        scores = torch.matmul(q, k.transpose(-2, -1)) / (self.head_dim ** 0.5)\n",
    "        piece_mask = piece_type.unsqueeze(1).unsqueeze(2).expand_as(scores)\n",
    "        scores = scores.masked_fill(piece_mask == 0, float('-inf'))\n",
    "        attention_weights = torch.softmax(scores, dim=-1)\n",
    "        self.attention_weights = attention_weights\n",
    "        \n",
    "        weighted_values = torch.matmul(attention_weights, v)\n",
    "        output = weighted_values.transpose(1, 2).contiguous().view(batch_size, seq_length, self.embedding_dim)\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, num_tokens, embedding_dim, num_heads, num_layers, hidden_dim, dropout):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_tokens, embedding_dim)\n",
    "        self.transformer_layers = nn.ModuleList([\n",
    "            nn.TransformerEncoderLayer(embedding_dim, num_heads, hidden_dim, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        self.piece_wise_attention = PieceWiseSelfAttention(embedding_dim, num_heads)\n",
    "        self.value_head = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.policy_head = nn.Sequential(\n",
    "            nn.Linear(embedding_dim + 1, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 64),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, piece_type):\n",
    "        x = self.embedding(x)\n",
    "        for layer in self.transformer_layers:\n",
    "            x = layer(x)\n",
    "        x = self.piece_wise_attention(x, piece_type)\n",
    "        value = self.value_head(x[:, -1])\n",
    "        policy_input = torch.cat((x[:, -1], value.view(-1, 1)), dim=-1)\n",
    "        policy = self.policy_head(policy_input)\n",
    "        return value, policy\n",
    "\n",
    "    def to(self, device):\n",
    "        super().to(device)\n",
    "        self.embedding = self.embedding.to(device)\n",
    "        self.transformer_layers = self.transformer_layers.to(device)\n",
    "        self.piece_wise_attention = self.piece_wise_attention.to(device)\n",
    "        self.value_head = self.value_head.to(device)\n",
    "        self.policy_head = self.policy_head.to(device)\n",
    "        return self\n",
    "\n",
    "def generate_piece_moves(board, piece_type, piece_index):\n",
    "    square = chess.SQUARES[piece_index]\n",
    "    piece = board.piece_at(square)\n",
    "    \n",
    "    if piece is None or piece.piece_type != piece_type:\n",
    "        return []\n",
    "    \n",
    "    legal_moves = []\n",
    "    \n",
    "    if piece_type == chess.PAWN:\n",
    "        for move in board.legal_moves:\n",
    "            if move.from_square == square:\n",
    "                legal_moves.append(move)\n",
    "    \n",
    "    elif piece_type == chess.KNIGHT:\n",
    "        for move in board.legal_moves:\n",
    "            if move.from_square == square:\n",
    "                legal_moves.append(move)\n",
    "    \n",
    "    elif piece_type == chess.BISHOP:\n",
    "        for move in board.legal_moves:\n",
    "            if move.from_square == square:\n",
    "                legal_moves.append(move)\n",
    "    \n",
    "    elif piece_type == chess.ROOK:\n",
    "        for move in board.legal_moves:\n",
    "            if move.from_square == square:\n",
    "                legal_moves.append(move)\n",
    "    \n",
    "    elif piece_type == chess.QUEEN:\n",
    "        for move in board.legal_moves:\n",
    "            if move.from_square == square:\n",
    "                legal_moves.append(move)\n",
    "    \n",
    "    elif piece_type == chess.KING:\n",
    "        for move in board.legal_moves:\n",
    "            if move.from_square == square:\n",
    "                legal_moves.append(move)\n",
    "    \n",
    "    return legal_moves\n",
    "\n",
    "def map_policy_to_move(board, policy_output, piece_type_tensor, attention_weights, top_k=5):\n",
    "    top_k_pieces = torch.topk(attention_weights.squeeze(), top_k)\n",
    "    top_k_indices = top_k_pieces.indices.flatten().tolist()\n",
    "    \n",
    "    candidate_moves = []\n",
    "    for piece_index in top_k_indices:\n",
    "        if piece_index < len(piece_type_tensor):\n",
    "            piece_type = piece_type_tensor[piece_index].item()\n",
    "            piece_moves = generate_piece_moves(board, piece_type, piece_index)\n",
    "            candidate_moves.extend(piece_moves)\n",
    "    \n",
    "    move_mapping = {i: move for i, move in enumerate(candidate_moves)}\n",
    "    \n",
    "    move_probabilities = policy_output.squeeze().tolist()\n",
    "    \n",
    "    best_move_index = move_probabilities.index(max(move_probabilities))\n",
    "    \n",
    "    best_move = move_mapping.get(best_move_index)\n",
    "    \n",
    "    return best_move\n",
    "\n",
    "def tokenize_board(board):\n",
    "    tokenized_board = []\n",
    "    piece_type_tensor = []\n",
    "\n",
    "    for square in chess.SQUARES:\n",
    "        piece = board.piece_at(square)\n",
    "\n",
    "        if piece:\n",
    "            piece_type = piece.piece_type\n",
    "            piece_color = piece.color\n",
    "\n",
    "            if piece_color == chess.WHITE:\n",
    "                token = piece_type\n",
    "            else:\n",
    "                token = piece_type + 6\n",
    "\n",
    "            piece_type_tensor.append(piece_type)\n",
    "        else:\n",
    "            token = 0\n",
    "            piece_type_tensor.append(0)\n",
    "\n",
    "        tokenized_board.append(token)\n",
    "\n",
    "    return tokenized_board, torch.tensor(piece_type_tensor)\n",
    "\n",
    "def fen_to_tensor(fen):\n",
    "    board = chess.Board(fen)\n",
    "    tokenized_board, piece_type_tensor = tokenize_board(board)\n",
    "    return torch.tensor(tokenized_board), piece_type_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5808afa3-3f22-4aa1-a431-e3ab233947cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def generate_self_play_data(model, num_games, max_moves_per_game):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    self_play_data = []\n",
    "\n",
    "    for game_number in range(1, num_games + 1):\n",
    "        board = chess.Board()\n",
    "        game_moves = []\n",
    "        game_values = []\n",
    "\n",
    "        for move_number in range(1, max_moves_per_game + 1):\n",
    "            if board.is_game_over():\n",
    "                break\n",
    "\n",
    "            fen = board.fen()\n",
    "            tokenized_board_tensor, piece_type_tensor = fen_to_tensor(fen)\n",
    "            tokenized_board_tensor = tokenized_board_tensor.to(device)\n",
    "            piece_type_tensor = piece_type_tensor.to(device)\n",
    "            \n",
    "            value, policy = model(tokenized_board_tensor.unsqueeze(0), piece_type_tensor.unsqueeze(0))\n",
    "            attention_weights = model.piece_wise_attention.attention_weights\n",
    "            move = map_policy_to_move(board, policy, piece_type_tensor, attention_weights)\n",
    "\n",
    "            if move is None:\n",
    "                break\n",
    "\n",
    "            board.push(move)\n",
    "            game_moves.append(move)\n",
    "            game_values.append(value.item())\n",
    "\n",
    "        result = board.result()\n",
    "        if result == '1-0':\n",
    "            game_result = 1.0\n",
    "            result_str = \"White wins\"\n",
    "        elif result == '0-1':\n",
    "            game_result = -1.0\n",
    "            result_str = \"Black wins\"\n",
    "        else:\n",
    "            game_result = 0.0\n",
    "            result_str = \"Draw\"\n",
    "\n",
    "        self_play_data.append((game_moves, game_values, game_result))\n",
    "        print(f\"Epoch: 1, Game: {game_number}, Result: {result_str}\")\n",
    "\n",
    "    return self_play_data\n",
    "\n",
    "\n",
    "def save_self_play_data(self_play_data, data_dir, file_prefix):\n",
    "    for idx, game_data in enumerate(self_play_data, 1):\n",
    "        game_moves, game_values, game_result = game_data\n",
    "        data_path = os.path.join(data_dir, f\"{file_prefix}_game_{idx}.txt\")\n",
    "        with open(data_path, \"w\") as file:\n",
    "            for move, value in zip(game_moves, game_values):\n",
    "                file.write(f\"{move.uci()} {value}\\n\")\n",
    "            file.write(f\"Result: {game_result}\\n\")\n",
    "    print(f\"Self-play data saved: {len(self_play_data)} games\")\n",
    "\n",
    "\n",
    "def load_self_play_data(data_dir, file_prefix):\n",
    "    self_play_data = []\n",
    "\n",
    "    # Get the list of files with the specified prefix\n",
    "    file_pattern = os.path.join(data_dir, f\"{file_prefix}_game_*.txt\")\n",
    "    game_files = glob.glob(file_pattern)\n",
    "\n",
    "    for game_file in game_files:\n",
    "        with open(game_file, \"r\") as file:\n",
    "            game_moves = []\n",
    "            game_values = []\n",
    "            for line in file:\n",
    "                if line.startswith(\"Result:\"):\n",
    "                    game_result = float(line.split(\":\")[1].strip())\n",
    "                else:\n",
    "                    move, value = line.strip().split()\n",
    "                    game_moves.append(chess.Move.from_uci(move))\n",
    "                    game_values.append(float(value))\n",
    "            self_play_data.append((game_moves, game_values, game_result))\n",
    "\n",
    "    return self_play_data\n",
    "\n",
    "def check_self_play_data_exists(data_dir, file_prefix):\n",
    "    file_pattern = os.path.join(data_dir, f\"{file_prefix}_game_*.txt\")\n",
    "    game_files = glob.glob(file_pattern)\n",
    "    return len(game_files) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5439f0c8-bb60-4398-81a7-6c64e1b4d096",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train(model, optimizer, num_epochs, batch_size, self_play_data, checkpoint_dir, data_dir, save_interval, window_size):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion_value = nn.MSELoss()\n",
    "\n",
    "    def window_loss_fn(values):\n",
    "        first_value = values[:, 0]\n",
    "        last_value = values[:, -1]\n",
    "        return torch.mean(torch.relu(first_value - last_value))\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        num_batches = 0\n",
    "        \n",
    "        for batch_idx in range(0, len(self_play_data), batch_size):\n",
    "            batch = self_play_data[batch_idx:batch_idx+batch_size]\n",
    "            boards = []\n",
    "            piece_types = []\n",
    "            value_targets = []\n",
    "\n",
    "            for game_moves, game_values, game_result in batch:\n",
    "                for move_idx, move in enumerate(game_moves):\n",
    "                    board = chess.Board()\n",
    "                    for prev_move in game_moves[:move_idx]:\n",
    "                        board.push(prev_move)\n",
    "                    fen = board.fen()\n",
    "                    tokenized_board_tensor, piece_type_tensor = fen_to_tensor(fen)\n",
    "                    boards.append(tokenized_board_tensor)\n",
    "                    piece_types.append(piece_type_tensor)\n",
    "\n",
    "                    # Calculate value targets based on the game result\n",
    "                    value_target = game_result if move_idx % 2 == 0 else -game_result\n",
    "                    value_targets.append(value_target)\n",
    "\n",
    "            boards = torch.stack(boards).to(device)\n",
    "            piece_types = torch.stack(piece_types).to(device)\n",
    "            value_targets = torch.tensor(value_targets).unsqueeze(1).to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            values, _ = model(boards, piece_types)\n",
    "\n",
    "            value_loss = criterion_value(values, value_targets)\n",
    "\n",
    "            # Calculate the window loss\n",
    "            window_boards = []\n",
    "            window_piece_types = []\n",
    "            window_values = []\n",
    "\n",
    "            for game_moves, game_values, game_result in batch:\n",
    "                for player in [0, 1]:  # Iterate over both players\n",
    "                    player_moves = game_moves[player::2]  # Select moves for the current player\n",
    "                    player_values = game_values[player::2]\n",
    "\n",
    "                    for move_idx in range(len(player_moves) - window_size + 1):\n",
    "                        window_moves = player_moves[move_idx:move_idx+window_size]\n",
    "                        window_values.extend(player_values[move_idx:move_idx+window_size])\n",
    "\n",
    "                        # Create board states for the window moves\n",
    "                        for move in window_moves:\n",
    "                            board = chess.Board()\n",
    "                            for prev_move in game_moves[:move_idx*2+player]:\n",
    "                                board.push(prev_move)\n",
    "                            fen = board.fen()\n",
    "                            tokenized_board_tensor, piece_type_tensor = fen_to_tensor(fen)\n",
    "                            window_boards.append(tokenized_board_tensor)\n",
    "                            window_piece_types.append(piece_type_tensor)\n",
    "\n",
    "            window_boards = torch.stack(window_boards).to(device)\n",
    "            window_piece_types = torch.stack(window_piece_types).to(device)\n",
    "            window_values_tensor = torch.tensor(window_values).unsqueeze(1).to(device)\n",
    "\n",
    "            _, window_values_pred = model(window_boards, window_piece_types)\n",
    "\n",
    "            num_windows = window_values_pred.size(0) // window_size\n",
    "            window_values_pred = window_values_pred[:num_windows * window_size].view(-1, window_size)\n",
    "            window_values_tensor = window_values_tensor[:num_windows * window_size].view(-1, window_size)\n",
    "            window_loss = window_loss_fn(window_values_pred)\n",
    "\n",
    "            loss = value_loss + window_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            num_batches += 1\n",
    "\n",
    "        epoch_loss /= num_batches\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.8f}, Value Loss: {value_loss:.8f}, Window Loss: {window_loss:.8f}\")\n",
    "\n",
    "        if (epoch + 1) % save_interval == 0:\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, f\"checkpoint_epoch_{epoch+1}.pth\")\n",
    "            torch.save({\n",
    "                \"epoch\": epoch + 1,\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                \"loss\": epoch_loss\n",
    "            }, checkpoint_path)\n",
    "            print(f\"Checkpoint saved at epoch {epoch+1}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "#################################### HYPER PARAMETERS --- do not edit num_tokens #############################\n",
    "model = TransformerModel(num_tokens=13, embedding_dim=128, num_heads=8, num_layers=8, hidden_dim=128, dropout=0.1)\n",
    "model = model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "num_self_play_games = 1000\n",
    "max_moves_per_game = 50\n",
    "num_epochs = 5\n",
    "batch_size = 25\n",
    "checkpoint_dir = \"checkpoints\"\n",
    "data_dir = \"self_play_data\"\n",
    "save_interval = 5\n",
    "\n",
    "#constant\n",
    "window_size = 10\n",
    "\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3e98c8-1e49-4f09-b694-932a1f3e89dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\n",
      "Epoch [1/5], Loss: 0.01861065, Value Loss: 0.00013456, Window Loss: 0.00000000\n",
      "Epoch [2/5], Loss: 0.00924258, Value Loss: 0.00001151, Window Loss: 0.00000000\n",
      "Epoch [3/5], Loss: 0.00923066, Value Loss: 0.00000730, Window Loss: 0.00000000\n",
      "Epoch [4/5], Loss: 0.00923347, Value Loss: 0.00000558, Window Loss: 0.00000000\n",
      "Epoch [5/5], Loss: 0.00923091, Value Loss: 0.00000664, Window Loss: 0.00000000\n",
      "Checkpoint saved at epoch 5\n",
      "Iteration: 2\n",
      "Epoch [1/5], Loss: 0.00000687, Value Loss: 0.00000705, Window Loss: 0.00000000\n",
      "Epoch [2/5], Loss: 0.00000577, Value Loss: 0.00000584, Window Loss: 0.00000000\n",
      "Epoch [3/5], Loss: 0.00000560, Value Loss: 0.00000550, Window Loss: 0.00000000\n",
      "Epoch [4/5], Loss: 0.00000542, Value Loss: 0.00000536, Window Loss: 0.00000000\n",
      "Epoch [5/5], Loss: 0.00000515, Value Loss: 0.00000509, Window Loss: 0.00000000\n",
      "Checkpoint saved at epoch 5\n",
      "Iteration: 3\n",
      "Epoch [1/5], Loss: 0.00000983, Value Loss: 0.00000983, Window Loss: 0.00000000\n",
      "Epoch [2/5], Loss: 0.00000618, Value Loss: 0.00000618, Window Loss: 0.00000000\n",
      "Epoch [3/5], Loss: 0.00001077, Value Loss: 0.00001077, Window Loss: 0.00000000\n",
      "Epoch [4/5], Loss: 0.00001151, Value Loss: 0.00001151, Window Loss: 0.00000000\n",
      "Epoch [5/5], Loss: 0.00000648, Value Loss: 0.00000648, Window Loss: 0.00000000\n",
      "Checkpoint saved at epoch 5\n",
      "Iteration: 4\n",
      "Epoch: 1, Game: 1, Result: Draw\n",
      "Epoch: 1, Game: 2, Result: Draw\n",
      "Epoch: 1, Game: 3, Result: Draw\n",
      "Epoch: 1, Game: 4, Result: Draw\n",
      "Epoch: 1, Game: 5, Result: Draw\n",
      "Epoch: 1, Game: 6, Result: Draw\n",
      "Epoch: 1, Game: 7, Result: Draw\n",
      "Epoch: 1, Game: 8, Result: Draw\n",
      "Epoch: 1, Game: 9, Result: Draw\n",
      "Epoch: 1, Game: 10, Result: Draw\n",
      "Epoch: 1, Game: 11, Result: Draw\n",
      "Epoch: 1, Game: 12, Result: Draw\n",
      "Epoch: 1, Game: 13, Result: Draw\n",
      "Epoch: 1, Game: 14, Result: Draw\n",
      "Epoch: 1, Game: 15, Result: Draw\n",
      "Epoch: 1, Game: 16, Result: Draw\n",
      "Epoch: 1, Game: 17, Result: Draw\n",
      "Epoch: 1, Game: 18, Result: Draw\n",
      "Epoch: 1, Game: 19, Result: Draw\n",
      "Epoch: 1, Game: 20, Result: Draw\n",
      "Epoch: 1, Game: 21, Result: Draw\n",
      "Epoch: 1, Game: 22, Result: Draw\n",
      "Epoch: 1, Game: 23, Result: Draw\n",
      "Epoch: 1, Game: 24, Result: Draw\n",
      "Epoch: 1, Game: 25, Result: Draw\n",
      "Epoch: 1, Game: 26, Result: Draw\n",
      "Epoch: 1, Game: 27, Result: Draw\n",
      "Epoch: 1, Game: 28, Result: Draw\n",
      "Epoch: 1, Game: 29, Result: Draw\n",
      "Epoch: 1, Game: 30, Result: Draw\n",
      "Epoch: 1, Game: 31, Result: Draw\n",
      "Epoch: 1, Game: 32, Result: Draw\n",
      "Epoch: 1, Game: 33, Result: Draw\n",
      "Epoch: 1, Game: 34, Result: Draw\n",
      "Epoch: 1, Game: 35, Result: Draw\n",
      "Epoch: 1, Game: 36, Result: Draw\n",
      "Epoch: 1, Game: 37, Result: Draw\n",
      "Epoch: 1, Game: 38, Result: Draw\n",
      "Epoch: 1, Game: 39, Result: Draw\n",
      "Epoch: 1, Game: 40, Result: Draw\n",
      "Epoch: 1, Game: 41, Result: Draw\n",
      "Epoch: 1, Game: 42, Result: Draw\n",
      "Epoch: 1, Game: 43, Result: Draw\n",
      "Epoch: 1, Game: 44, Result: Draw\n",
      "Epoch: 1, Game: 45, Result: Draw\n",
      "Epoch: 1, Game: 46, Result: Draw\n",
      "Epoch: 1, Game: 47, Result: Draw\n",
      "Epoch: 1, Game: 48, Result: Draw\n",
      "Epoch: 1, Game: 49, Result: Draw\n",
      "Epoch: 1, Game: 50, Result: Draw\n",
      "Epoch: 1, Game: 51, Result: Draw\n",
      "Epoch: 1, Game: 52, Result: Draw\n",
      "Epoch: 1, Game: 53, Result: Draw\n",
      "Epoch: 1, Game: 54, Result: Draw\n",
      "Epoch: 1, Game: 55, Result: Draw\n",
      "Epoch: 1, Game: 56, Result: Draw\n",
      "Epoch: 1, Game: 57, Result: Draw\n",
      "Epoch: 1, Game: 58, Result: Draw\n",
      "Epoch: 1, Game: 59, Result: Draw\n",
      "Epoch: 1, Game: 60, Result: Draw\n",
      "Epoch: 1, Game: 61, Result: Draw\n",
      "Epoch: 1, Game: 62, Result: Draw\n",
      "Epoch: 1, Game: 63, Result: Draw\n",
      "Epoch: 1, Game: 64, Result: Draw\n",
      "Epoch: 1, Game: 65, Result: Draw\n",
      "Epoch: 1, Game: 66, Result: Draw\n",
      "Epoch: 1, Game: 67, Result: Draw\n",
      "Epoch: 1, Game: 68, Result: Draw\n",
      "Epoch: 1, Game: 69, Result: Draw\n",
      "Epoch: 1, Game: 70, Result: Draw\n",
      "Epoch: 1, Game: 71, Result: Draw\n",
      "Epoch: 1, Game: 72, Result: Draw\n",
      "Epoch: 1, Game: 73, Result: Draw\n",
      "Epoch: 1, Game: 74, Result: Draw\n",
      "Epoch: 1, Game: 75, Result: Draw\n",
      "Epoch: 1, Game: 76, Result: Draw\n",
      "Epoch: 1, Game: 77, Result: Draw\n",
      "Epoch: 1, Game: 78, Result: Draw\n",
      "Epoch: 1, Game: 79, Result: Draw\n",
      "Epoch: 1, Game: 80, Result: Draw\n",
      "Epoch: 1, Game: 81, Result: Draw\n",
      "Epoch: 1, Game: 82, Result: Draw\n",
      "Epoch: 1, Game: 83, Result: Draw\n",
      "Epoch: 1, Game: 84, Result: Draw\n",
      "Epoch: 1, Game: 85, Result: Draw\n",
      "Epoch: 1, Game: 86, Result: Draw\n",
      "Epoch: 1, Game: 87, Result: Draw\n",
      "Epoch: 1, Game: 88, Result: Draw\n",
      "Epoch: 1, Game: 89, Result: Draw\n",
      "Epoch: 1, Game: 90, Result: Draw\n",
      "Epoch: 1, Game: 91, Result: Draw\n",
      "Epoch: 1, Game: 92, Result: Draw\n",
      "Epoch: 1, Game: 93, Result: Draw\n",
      "Epoch: 1, Game: 94, Result: Draw\n",
      "Epoch: 1, Game: 95, Result: Draw\n",
      "Epoch: 1, Game: 96, Result: Draw\n",
      "Epoch: 1, Game: 97, Result: Draw\n",
      "Epoch: 1, Game: 98, Result: Draw\n",
      "Epoch: 1, Game: 99, Result: Draw\n",
      "Epoch: 1, Game: 100, Result: Draw\n",
      "Epoch: 1, Game: 101, Result: Draw\n",
      "Epoch: 1, Game: 102, Result: Draw\n",
      "Epoch: 1, Game: 103, Result: Draw\n",
      "Epoch: 1, Game: 104, Result: Draw\n",
      "Epoch: 1, Game: 105, Result: Draw\n",
      "Epoch: 1, Game: 106, Result: Draw\n",
      "Epoch: 1, Game: 107, Result: Draw\n",
      "Epoch: 1, Game: 108, Result: Draw\n",
      "Epoch: 1, Game: 109, Result: Draw\n",
      "Epoch: 1, Game: 110, Result: Draw\n",
      "Epoch: 1, Game: 111, Result: Draw\n",
      "Epoch: 1, Game: 112, Result: Draw\n",
      "Epoch: 1, Game: 113, Result: Draw\n",
      "Epoch: 1, Game: 114, Result: Draw\n",
      "Epoch: 1, Game: 115, Result: Draw\n",
      "Epoch: 1, Game: 116, Result: Draw\n",
      "Epoch: 1, Game: 117, Result: Draw\n",
      "Epoch: 1, Game: 118, Result: Draw\n",
      "Epoch: 1, Game: 119, Result: Draw\n",
      "Epoch: 1, Game: 120, Result: Draw\n",
      "Epoch: 1, Game: 121, Result: Draw\n",
      "Epoch: 1, Game: 122, Result: Draw\n",
      "Epoch: 1, Game: 123, Result: Draw\n",
      "Epoch: 1, Game: 124, Result: Draw\n",
      "Epoch: 1, Game: 125, Result: Draw\n",
      "Epoch: 1, Game: 126, Result: Draw\n",
      "Epoch: 1, Game: 127, Result: Draw\n",
      "Epoch: 1, Game: 128, Result: Draw\n",
      "Epoch: 1, Game: 129, Result: Draw\n",
      "Epoch: 1, Game: 130, Result: Draw\n",
      "Epoch: 1, Game: 131, Result: Draw\n",
      "Epoch: 1, Game: 132, Result: Draw\n",
      "Epoch: 1, Game: 133, Result: Draw\n",
      "Epoch: 1, Game: 134, Result: Draw\n",
      "Epoch: 1, Game: 135, Result: Draw\n",
      "Epoch: 1, Game: 136, Result: Draw\n",
      "Epoch: 1, Game: 137, Result: Draw\n",
      "Epoch: 1, Game: 138, Result: Draw\n",
      "Epoch: 1, Game: 139, Result: Draw\n",
      "Epoch: 1, Game: 140, Result: Draw\n",
      "Epoch: 1, Game: 141, Result: Draw\n",
      "Epoch: 1, Game: 142, Result: Draw\n",
      "Epoch: 1, Game: 143, Result: Draw\n",
      "Epoch: 1, Game: 144, Result: Draw\n",
      "Epoch: 1, Game: 145, Result: Draw\n",
      "Epoch: 1, Game: 146, Result: Draw\n",
      "Epoch: 1, Game: 147, Result: Draw\n",
      "Epoch: 1, Game: 148, Result: Draw\n"
     ]
    }
   ],
   "source": [
    "num_iterations = 5  # Number of times to iterate between self-play and training\n",
    "\n",
    "for iteration in range(num_iterations):\n",
    "    print(f\"Iteration: {iteration + 1}\")\n",
    "\n",
    "    # Check if self-play data exists for the current iteration\n",
    "    file_prefix = f\"self_play_iter_{iteration + 1}\"\n",
    "    self_play_data_exists = check_self_play_data_exists(data_dir, file_prefix)\n",
    "\n",
    "    if self_play_data_exists:\n",
    "        # Load self-play data for the current iteration\n",
    "        self_play_data = load_self_play_data(data_dir, file_prefix)\n",
    "    else:\n",
    "        # Generate self-play data for the current iteration\n",
    "        self_play_data = generate_self_play_data(model, num_self_play_games, max_moves_per_game)\n",
    "        save_self_play_data(self_play_data, data_dir, file_prefix)\n",
    "\n",
    "    # Train the model\n",
    "    trained_model = train(model, optimizer, num_epochs, batch_size, self_play_data, checkpoint_dir, data_dir, save_interval, window_size)\n",
    "\n",
    "    # Update the model for the next iteration\n",
    "    model = trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5c11ed-981c-4bf0-9ea6-4b58bb081edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906e24cd-fb56-450f-ac76-8ade00960f5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
